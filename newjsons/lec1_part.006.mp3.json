{
    "chunks": [
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 0.0,
            "end": 13.64,
            "text": " a piece of software would do what it's supposed to do  and would not make it, and that there are no bugs in it.  But now that we're going to start  to bring data and machine learning algorithms  into the picture, we are really suffering"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 13.64,
            "end": 27.88,
            "text": " for a lack of good tools for doing  similar formal checking of our algorithms and their behavior.  And so this is going to be really important  in the future decade as machine learning gets deployed,  not just in settings like health care,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 27.88,
            "end": 39.019999999999996,
            "text": " but also in other settings of life and death,  such as in autonomous driving.  And it's something that we'll touch on  throughout the semester.  So for example, when one deploys machine learning algorithms,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 39.019999999999996,
            "end": 52.2,
            "text": " we need to be thinking about, are they safe?  But also, how do we check for safety long term?  What are checks and balances that we  should put into the deployment of the algorithm  to make sure that it's still working as it was intended?"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 52.2,
            "end": 64.75999999999999,
            "text": " We also need fair and accountable algorithms,  because increasingly, machine learning results  are being used to drive resources in a health care  setting.  An example that I'll discuss in about a week and a half"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 64.75999999999999,
            "end": 78.4,
            "text": " when we talk about risk stratification  is that algorithms are being used by payers  to risk stratify patients.  For example, to figure out which patients are likely to be  readmitted to the hospital in the next 30 days,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 78.4,
            "end": 89.8,
            "text": " are likely to have undiagnosed diabetes,  are likely to progress quickly in their diabetes.  And based on those predictions, they're  doing a number of interventions.  For example, they might send nurses to the patient's home."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 89.8,
            "end": 104.56,
            "text": " They might offer their members access  to a weight loss program.  And each of these interventions has money associated to them,  if they have a cost.  And so you can't do them for everyone."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 104.56,
            "end": 120.68,
            "text": " And so one uses machine learning algorithms  to prioritize, who do you give those interventions to?  But because health is so intimately tied  to socioeconomic status, one could  think about what happens if these algorithms are not fair."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 120.68,
            "end": 134.84,
            "text": " It could have really long-term implications for our society,  and something that we're going to talk about later  in the semester as well.  Now, I mentioned earlier that many of the questions  that we need to study in this field"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 134.84,
            "end": 144.70000000000002,
            "text": " don't have good label data.  In cases where we know what we want to predict,  it's a supervised prediction problem,  often we just don't have labels for that thing  we want to predict."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 144.70000000000002,
            "end": 154.58,
            "text": " But in also many situations, we're  not interested in just predicting something.  We're interested in discovery.  So for example, when I talk about disease subtyping  or disease progression, it's much harder"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 154.58,
            "end": 164.34,
            "text": " to quantify what you're looking for.  And so unsupervised learning algorithms  are going to be really important for what we do.  And finally, I already mentioned how many of the questions  we want to answer are causal in nature,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 164.34,
            "end": 175.9,
            "text": " particularly when you want to think about treatment  strategies.  And so we'll have two lectures on causal inference,  and we'll have two lectures on reinforcement learning,  which is increasingly being used to learn treatment"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 175.9,
            "end": 199.06,
            "text": " policies in health care.  So all of these different problems  that we've talked about result in our having  to rethink how do we do machine learning in this setting.  For example, because driving labels"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 199.06,
            "end": 214.2,
            "text": " for supervised prediction is very hard,  one has to think through how can we automatically  build algorithms to do what's called electronic phenotyping,  to discover, to figure out automatically  what is the relevant labels for a set of patients"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 214.2,
            "end": 228.02,
            "text": " that one could then attempt to predict in the future.  Because we often have very little data, for example,  some rare diseases, there might only  be a few hundred or a few thousand people in the nation  that have that disease."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 228.02,
            "end": 240.86,
            "text": " Some common diseases present in very diverse ways,  and thus, in essence, are very rare.  Because of that, you have just a small number of patient samples  that you could get, even if you had all the data  in the right place."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 240.86,
            "end": 256.14,
            "text": " And so we need to think through how can we bring through,  how can we bring together domain knowledge?  How can we bring together data from other areas?  Well, everyone look over here now.  From other areas, other diseases,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 256.14,
            "end": 275.74,
            "text": " in order to learn something that then we  could refine for the foreground question of interest.  Finally, there's a ton of missing data in health care.  So raise your hand if you've only  been seeing your current primary care physician for less"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 275.74,
            "end": 293.74,
            "text": " than four years.  OK, now this is an easy guess, because all of you  are students, and you probably don't live in Boston.  But here in the US, even after you graduate,  you go out into the world, you have a job,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 293.74,
            "end": 300.65999999999997,
            "text": " and that job pays your health insurance.  And you know what?  Most of you are going to go into the tech industry,  and most of you are going to switch jobs every four years.  And so your health insurance is going"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 300.65999999999997,
            "end": 311.42,
            "text": " to change every four years.  And unfortunately, data doesn't tend to follow people  when you change providers or payers.  And so what that means is, for any one thing  we might want to study, we tend to not"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 311.42,
            "end": 326.54,
            "text": " have very good longitudinal data on those individuals,  at least not here in the United States.  That story is a little bit different in other places  like the UK or Israel, for example.  Moreover, we also have a very bad lens"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 326.54,
            "end": 337.24,
            "text": " on that health care data.  So even if you've been going to the same doctor for a while,  we tend to only have data on you when  something's been recorded.  So if you went to a doctor, you had a lab test performed,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 337.24,
            "end": 349.02,
            "text": " we know the results of it.  If you never got your glucose tested,  it's very hard, though not impossible,  to figure out if you might be diabetic.  So thinking about how do we deal with the fact"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 349.02,
            "end": 362.1,
            "text": " that there's a large amount of missing data,  where that missing data has very different patterns  across patients, and where there might  be a big difference between train and test distributions,  is going to be a major part of what we discussed"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 362.1,
            "end": 374.41999999999996,
            "text": " in this course.  And finally, the last example is censoring.  I think I've said finally a few times.  So censoring, which we'll talk about in two weeks,  is what happens when you have data only"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 374.41999999999996,
            "end": 389.53999999999996,
            "text": " for small windows of time.  So for example, you have a data set where your goal is  to say predict survival.  So you want to know how long until a person dies,  but you only have data on them up to January 2009,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 389.53999999999996,
            "end": 400.7,
            "text": " and they haven't yet died by January 2009.  Then that individual is censored.  You don't know when they died.  So that doesn't mean you should throw away that data point.  In fact, we'll talk about learning algorithms"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 400.7,
            "end": 414.98,
            "text": " that can learn from censored data very effectively.  So there are a number of also logistical challenges  to doing machine learning in health care.  I talked about how having access to data is so important,  but one of the reasons, there are others,"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 414.98,
            "end": 429.26,
            "text": " for why getting large amounts of data in the public domain  is challenging is because it's so sensitive.  And removing identifiers, like name and social,  from data, which includes free text notes,  can be very challenging."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 429.26,
            "end": 444.86,
            "text": " And as a result, when we do research here at MIT,  typically it takes us anywhere from a few months, which  has never happened, to two years, which  is the usual situation, to negotiate a data sharing  agreement to get the health data to MIT to do research on."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 444.86,
            "end": 455.94,
            "text": " And of course, then my students write code,  which we're very happy to open source under MIT license,  but that code is completely useless  because no one can reproduce our results on the same data  because they don't have access to it."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 455.94,
            "end": 468.96000000000004,
            "text": " So that's a major challenge to this field.  Another challenge is about the difficulty in deploying  machine learning algorithms due to the challenge  of integration.  So you build a good algorithm, you"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 468.96000000000004,
            "end": 483.5,
            "text": " want to deploy it at your favorite hospital,  but guess what?  That hospital has Epic or Cerner or Athena  or some other commercial electronic medical records  system, and that electronic medical records system"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 483.5,
            "end": 507.58,
            "text": " is not built for your algorithm to plug into.  So there's a big gap, a large amount of difficulty  to getting your algorithms into production systems, which  we'll talk about as well during the semester.  So the goals that Pete and I have for you are as follows."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 507.58,
            "end": 525.24,
            "text": " We want you to get intuition for working with health care data.  And so the next two lectures after today  are going to focus on what health care is really like  and what is the health care data that's  created by the practice of health care like."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 525.24,
            "end": 538.64,
            "text": " We want you to get intuition for how  to formalize machine learning challenges as health care  problems, and that formalization step is often the most tricky  and it's something that you'll spend a lot of time thinking  through as part of your problem sets."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 538.64,
            "end": 554.56,
            "text": " Not all machine learning algorithms are equally useful.  And so one theme that I'll return to throughout  this semester is that despite the fact that deep learning is  good for many speech recognition and computer vision problems,  it actually isn't the best match to many problems in health care"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 554.56,
            "end": 567.6,
            "text": " and you'll explore that also as part of your problem sets  or at least one of them.  And we want you to understand also the subtleties  in robustly and safely deploying machine learning algorithms.  Now, more broadly, this is a young field."
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 568.44,
            "end": 588.6800000000001,
            "text": " For example, just recently, just about three years ago,  was created the first conference on machine learning  in health care by that name.  And new publication venues are being created every single day  by Nature, Lancet, and also machine learning journals"
        },
        {
            "number": "lec1",
            "title": "part.006.mp3",
            "start": 588.6800000000001,
            "end": 601.6,
            "text": " for publishing research on machine learning health care.  Because of some of the issues we talked about,  access to data, not very good benchmarks,  reproducibility."
        }
    ],
    "text": " a piece of software would do what it's supposed to do and would not make it, and that there are no bugs in it. But now that we're going to start to bring data and machine learning algorithms into the picture, we are really suffering for a lack of good tools for doing similar formal checking of our algorithms and their behavior. And so this is going to be really important in the future decade as machine learning gets deployed, not just in settings like health care, but also in other settings of life and death, such as in autonomous driving. And it's something that we'll touch on throughout the semester. So for example, when one deploys machine learning algorithms, we need to be thinking about, are they safe? But also, how do we check for safety long term? What are checks and balances that we should put into the deployment of the algorithm to make sure that it's still working as it was intended? We also need fair and accountable algorithms, because increasingly, machine learning results are being used to drive resources in a health care setting. An example that I'll discuss in about a week and a half when we talk about risk stratification is that algorithms are being used by payers to risk stratify patients. For example, to figure out which patients are likely to be readmitted to the hospital in the next 30 days, are likely to have undiagnosed diabetes, are likely to progress quickly in their diabetes. And based on those predictions, they're doing a number of interventions. For example, they might send nurses to the patient's home. They might offer their members access to a weight loss program. And each of these interventions has money associated to them, if they have a cost. And so you can't do them for everyone. And so one uses machine learning algorithms to prioritize, who do you give those interventions to? But because health is so intimately tied to socioeconomic status, one could think about what happens if these algorithms are not fair. It could have really long-term implications for our society, and something that we're going to talk about later in the semester as well. Now, I mentioned earlier that many of the questions that we need to study in this field don't have good label data. In cases where we know what we want to predict, it's a supervised prediction problem, often we just don't have labels for that thing we want to predict. But in also many situations, we're not interested in just predicting something. We're interested in discovery. So for example, when I talk about disease subtyping or disease progression, it's much harder to quantify what you're looking for. And so unsupervised learning algorithms are going to be really important for what we do. And finally, I already mentioned how many of the questions we want to answer are causal in nature, particularly when you want to think about treatment strategies. And so we'll have two lectures on causal inference, and we'll have two lectures on reinforcement learning, which is increasingly being used to learn treatment policies in health care. So all of these different problems that we've talked about result in our having to rethink how do we do machine learning in this setting. For example, because driving labels for supervised prediction is very hard, one has to think through how can we automatically build algorithms to do what's called electronic phenotyping, to discover, to figure out automatically what is the relevant labels for a set of patients that one could then attempt to predict in the future. Because we often have very little data, for example, some rare diseases, there might only be a few hundred or a few thousand people in the nation that have that disease. Some common diseases present in very diverse ways, and thus, in essence, are very rare. Because of that, you have just a small number of patient samples that you could get, even if you had all the data in the right place. And so we need to think through how can we bring through, how can we bring together domain knowledge? How can we bring together data from other areas? Well, everyone look over here now. From other areas, other diseases, in order to learn something that then we could refine for the foreground question of interest. Finally, there's a ton of missing data in health care. So raise your hand if you've only been seeing your current primary care physician for less than four years. OK, now this is an easy guess, because all of you are students, and you probably don't live in Boston. But here in the US, even after you graduate, you go out into the world, you have a job, and that job pays your health insurance. And you know what? Most of you are going to go into the tech industry, and most of you are going to switch jobs every four years. And so your health insurance is going to change every four years. And unfortunately, data doesn't tend to follow people when you change providers or payers. And so what that means is, for any one thing we might want to study, we tend to not have very good longitudinal data on those individuals, at least not here in the United States. That story is a little bit different in other places like the UK or Israel, for example. Moreover, we also have a very bad lens on that health care data. So even if you've been going to the same doctor for a while, we tend to only have data on you when something's been recorded. So if you went to a doctor, you had a lab test performed, we know the results of it. If you never got your glucose tested, it's very hard, though not impossible, to figure out if you might be diabetic. So thinking about how do we deal with the fact that there's a large amount of missing data, where that missing data has very different patterns across patients, and where there might be a big difference between train and test distributions, is going to be a major part of what we discussed in this course. And finally, the last example is censoring. I think I've said finally a few times. So censoring, which we'll talk about in two weeks, is what happens when you have data only for small windows of time. So for example, you have a data set where your goal is to say predict survival. So you want to know how long until a person dies, but you only have data on them up to January 2009, and they haven't yet died by January 2009. Then that individual is censored. You don't know when they died. So that doesn't mean you should throw away that data point. In fact, we'll talk about learning algorithms that can learn from censored data very effectively. So there are a number of also logistical challenges to doing machine learning in health care. I talked about how having access to data is so important, but one of the reasons, there are others, for why getting large amounts of data in the public domain is challenging is because it's so sensitive. And removing identifiers, like name and social, from data, which includes free text notes, can be very challenging. And as a result, when we do research here at MIT, typically it takes us anywhere from a few months, which has never happened, to two years, which is the usual situation, to negotiate a data sharing agreement to get the health data to MIT to do research on. And of course, then my students write code, which we're very happy to open source under MIT license, but that code is completely useless because no one can reproduce our results on the same data because they don't have access to it. So that's a major challenge to this field. Another challenge is about the difficulty in deploying machine learning algorithms due to the challenge of integration. So you build a good algorithm, you want to deploy it at your favorite hospital, but guess what? That hospital has Epic or Cerner or Athena or some other commercial electronic medical records system, and that electronic medical records system is not built for your algorithm to plug into. So there's a big gap, a large amount of difficulty to getting your algorithms into production systems, which we'll talk about as well during the semester. So the goals that Pete and I have for you are as follows. We want you to get intuition for working with health care data. And so the next two lectures after today are going to focus on what health care is really like and what is the health care data that's created by the practice of health care like. We want you to get intuition for how to formalize machine learning challenges as health care problems, and that formalization step is often the most tricky and it's something that you'll spend a lot of time thinking through as part of your problem sets. Not all machine learning algorithms are equally useful. And so one theme that I'll return to throughout this semester is that despite the fact that deep learning is good for many speech recognition and computer vision problems, it actually isn't the best match to many problems in health care and you'll explore that also as part of your problem sets or at least one of them. And we want you to understand also the subtleties in robustly and safely deploying machine learning algorithms. Now, more broadly, this is a young field. For example, just recently, just about three years ago, was created the first conference on machine learning in health care by that name. And new publication venues are being created every single day by Nature, Lancet, and also machine learning journals for publishing research on machine learning health care. Because of some of the issues we talked about, access to data, not very good benchmarks, reproducibility."
}